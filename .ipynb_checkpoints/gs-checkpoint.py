# import os
# import torch
# import imageio
# from PIL import Image
# from tqdm import tqdm
# import numpy as np

# # --- ç¯å¢ƒè®¾ç½® ---
# os.environ['ATTN_BACKEND'] = 'xformers'
# os.environ['SPCONV_ALGO'] = 'native'

# from trellis.pipelines import TrellisImageTo3DPipeline
# from trellis.utils import render_utils
# from trellis.modules import sparse as sp

# def visualize_gs_stage_evolution(
#     pipeline: TrellisImageTo3DPipeline,
#     image: Image.Image,
#     seed: int = 42,
#     steps: int = 50,
#     cfg_strength: float = 7.5
# ):
#     """
#     ä»ä¸€ä¸ªå›ºå®šçš„ç›¸æœºæœºä½ï¼Œæ¸²æŸ“å¹¶ä¿å­˜æ¯ä¸ªé‡‡æ ·æ­¥éª¤çš„é™æ€æ³•çº¿è´´å›¾ã€‚
#     """
#     print("å¼€å§‹å¯è§†åŒ–ç¨€ç–ç»“æ„ç”Ÿæˆè¿‡ç¨‹ (å›ºå®šæœºä½ï¼Œé€å¸§ä¿å­˜)...")
#     torch.manual_seed(seed)

#     # --- æ–°å¢ï¼šä¸ºä¿å­˜å›¾ç‰‡åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ ---
#     output_dir = "render_steps"
#     os.makedirs(output_dir, exist_ok=True)
#     print(f"æ¸²æŸ“çš„å›¾ç‰‡å°†ä¿å­˜åœ¨ '{output_dir}/' æ–‡ä»¶å¤¹ä¸­ã€‚")

#     print("1. é¢„å¤„ç†å›¾åƒå¹¶è·å–æ¡ä»¶...")
#     processed_image = pipeline.preprocess_image(image)
#     cond = pipeline.get_cond([processed_image])

#     print("2. å‡†å¤‡æ‰‹åŠ¨å¾ªç¯å’Œå›ºå®šç›¸æœº...")
#     flow_model = pipeline.models['sparse_structure_flow_model']
#     sampler = pipeline.sparse_structure_sampler
#     decoder = pipeline.models['sparse_structure_decoder']
    
#     # --- æ–°å¢ï¼šå®šä¹‰å›ºå®šçš„ç›¸æœºå‚æ•° ---
#     fixed_yaw = 180.0
#     fixed_pitch = 0.0
#     fixed_r = 2.5
#     fixed_fov = 40.0

#     # --- æ–°å¢ï¼šåœ¨å¾ªç¯å¤–é¢„å…ˆè®¡ç®—ä¸€æ¬¡ç›¸æœºçŸ©é˜µ ---
#     # æ³¨æ„ï¼šrender_frames æœŸæœ›çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼ å…¥åˆ—è¡¨
#     fixed_extrinsics, fixed_intrinsics = render_utils.yaw_pitch_r_fov_to_extrinsics_intrinsics(
#         [fixed_yaw], [fixed_pitch], [fixed_r], [fixed_fov]
#     )
    
#     reso = flow_model.resolution
#     noise = torch.randn(1, flow_model.in_channels, reso, reso, reso).to(pipeline.device)
    
#     t_seq = np.linspace(1, 0, steps + 1)
#     t_pairs = list((t_seq[i], t_seq[i + 1]) for i in range(steps))
    
#     x_t = noise

#     print("3. å¼€å§‹æ‰‹åŠ¨æ‰§è¡Œé‡‡æ ·å¾ªç¯å¹¶é€å¸§æ¸²æŸ“/ä¿å­˜...")
#     for i, (t_cur, t_prev) in enumerate(tqdm(t_pairs, desc="æ‰‹åŠ¨é‡‡æ ·ä¸­")):

#         with torch.no_grad():
#             out = sampler.sample_once(
#                 model=flow_model, x_t=x_t, t=t_cur, t_prev=t_prev,
#                 cond=cond['cond'], neg_cond=cond['neg_cond'],
#                 cfg_strength=cfg_strength, cfg_interval=[0, 1]
#             )
#         x_t = out.pred_x_prev
        
#         with torch.no_grad():
#             coords = torch.argwhere(decoder(x_t) > 0)
#             if coords.shape[0] == 0:
#                 continue
#             coords = coords[:, [0, 2, 3, 4]].int()

#             slat_feature_dim = pipeline.models['slat_flow_model'].in_channels
#             zero_feats = torch.zeros(coords.shape[0], slat_feature_dim, device=pipeline.device)
#             dummy_slat = sp.SparseTensor(feats=zero_feats, coords=coords)

#             decoded_output = pipeline.decode_slat(dummy_slat, formats=['mesh'])
#             mesh_result = decoded_output['mesh'][0]

#             # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ›¿æ¢ render_video ä¸º render_frames ---
#             render_output = render_utils.render_frames(
#                 sample=mesh_result, 
#                 extrinsics=fixed_extrinsics, 
#                 intrinsics=fixed_intrinsics,
#                 options={'resolution': 512, 'bg_color': (0,0,0)},
#                 verbose=False # åœ¨å¾ªç¯ä¸­å…³é—­æ¸²æŸ“è¿›åº¦æ¡
#             )
            
#             normal_frames = render_output.get('normal', [])
            
#             if normal_frames:
#                 # --- æ ¸å¿ƒä¿®æ”¹ï¼šä¿å­˜å•å¼ å›¾ç‰‡è€Œä¸æ˜¯æ·»åŠ åˆ°è§†é¢‘åˆ—è¡¨ ---
#                 frame_array = normal_frames[0] # è·å–åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å¼ ï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€å¼ ï¼‰å›¾ç‰‡

#                 # ä¸ºä¿é™©èµ·è§ï¼Œä¿ç•™é€šé“é¡ºåºä¿®æ­£é€»è¾‘
#                 if frame_array.ndim == 3 and frame_array.shape[0] == 3:
#                     frame_array = frame_array.transpose(1, 2, 0)

#                 # ç¡®ä¿å½¢çŠ¶æ˜¯ (H, W, C)
#                 if frame_array.ndim == 3 and frame_array.shape[2] in [1, 3, 4]:
#                     # ä½¿ç”¨ :03d æ ¼å¼åŒ–æ–‡ä»¶åï¼Œæ–¹ä¾¿æ’åº (e.g., step_001.png, step_010.png)
#                     output_path = os.path.join(output_dir, f"step_{i+1:03d}.png")
#                     imageio.imwrite(output_path, frame_array)
#                     print(f"\næ­¥éª¤ {i + 1}/{steps}: å·²ä¿å­˜æ¸²æŸ“å›¾ç‰‡åˆ° {output_path}")

#     print("\nğŸ‰ å…¨éƒ¨æ­¥éª¤æ¸²æŸ“å®Œæˆï¼")

# if __name__ == '__main__':
#     print("æ­£åœ¨åŠ è½½ Pipeline æ¨¡å‹...")
#     pipeline = TrellisImageTo3DPipeline.from_pretrained("microsoft/TRELLIS-image-large")
#     pipeline.cuda()

#     print("æ­£åœ¨åŠ è½½å›¾åƒ...")
#     try:
#         image = Image.open("./assets/example_image/typical_creature_rock_monster.png")
#     except FileNotFoundError:
#         print("\né”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¤ºä¾‹å›¾ç‰‡ï¼Œè¯·ç¡®ä¿ './assets/example_image/typical_creature_rock_monster.png' è·¯å¾„æ­£ç¡®ã€‚")
#         exit()

#     visualize_gs_stage_evolution(
#         pipeline,
#         image,
#         seed=42,
#         steps=50,
#         cfg_strength=7.5
#     )

import os
import torch
from PIL import Image
from tqdm import tqdm
import numpy as np

# --- ç¯å¢ƒè®¾ç½® ---
os.environ['ATTN_BACKEND'] = 'xformers'
os.environ['SPCONV_ALGO'] = 'native'

from trellis.pipelines import TrellisImageTo3DPipeline

def save_intermediate_tokens_for_analysis(
    pipeline: TrellisImageTo3DPipeline,
    image: Image.Image,
    seed: int = 42,
    steps: int = 50,
    cfg_strength: float = 7.5
):
    """
    éå†æ‰€æœ‰å»å™ªæ­¥éª¤ï¼Œåœ¨æ¯ä¸€æ­¥ä¸­æ•è·å¹¶å­˜å‚¨æ‰€æœ‰ä¸­é—´blockçš„ç‰¹å¾(tokens)ã€‚
    """
    print("å¼€å§‹é‡‡é›†æ‰€æœ‰æ­¥éª¤å’Œæ‰€æœ‰ä¸­é—´å±‚çš„Tokens...")
    torch.manual_seed(seed)

    # 1. é¢„å¤„ç†å›¾åƒå¹¶è·å–æ¡ä»¶
    print("1. é¢„å¤„ç†å›¾åƒå¹¶è·å–æ¡ä»¶...")
    processed_image = pipeline.preprocess_image(image)
    cond = pipeline.get_cond([processed_image])

    # 2. å‡†å¤‡æ‰‹åŠ¨å¾ªç¯
    print("2. å‡†å¤‡æ‰‹åŠ¨å¾ªç¯...")
    flow_model = pipeline.models['sparse_structure_flow_model']
    sampler = pipeline.sparse_structure_sampler
    
    reso = flow_model.resolution
    noise = torch.randn(1, flow_model.in_channels, reso, reso, reso).to(pipeline.device)
    
    t_seq = np.linspace(1, 0, steps + 1)
    t_pairs = list((t_seq[i], t_seq[i + 1]) for i in range(steps))
    
    x_t = noise
    
    # æ ¸å¿ƒæ•°æ®ç»“æ„ï¼šç”¨ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ‰€æœ‰æ•°æ®
    # ç»“æ„: {step_index: [block_2_features, block_4_features, ...]}
    all_steps_features = {}

    # 3. å¼€å§‹æ‰‹åŠ¨æ‰§è¡Œé‡‡æ ·å¾ªç¯å¹¶ä¿å­˜ä¸­é—´Tokens
    print("3. å¼€å§‹æ‰‹åŠ¨æ‰§è¡Œé‡‡æ ·å¾ªç¯...")
    for i, (t_cur, t_prev) in enumerate(tqdm(t_pairs, desc="æ­£åœ¨é‡‡é›†Tokens")):
        
        with torch.no_grad():
            # è·å–å½“å‰æ—¶é—´æ­¥çš„å¼ é‡è¡¨ç¤º
            t_cur_tensor = torch.tensor([1000 * t_cur] * x_t.shape[0], device=x_t.device)
            
            # (A) è°ƒç”¨æˆ‘ä»¬ä¿®æ”¹åçš„ forward å‡½æ•°ï¼Œç›´æ¥ä»å½“å‰ x_t è·å–ä¸­é—´ç‰¹å¾
            _, intermediate_features = flow_model(
                x_t, 
                t_cur_tensor, 
                cond['cond'], # è¿™é‡Œåªç”¨æ­£å‘æ¡ä»¶æ¥è·å–ç‰¹å¾
                output_intermediate_features=True
            )
            
            # å°†è·å–åˆ°çš„ç‰¹å¾åˆ—è¡¨å­˜å…¥æˆ‘ä»¬çš„ä¸»å­—å…¸ä¸­
            # .cpu() æ˜¯ä¸ºäº†å°†æ•°æ®ä»æ˜¾å­˜è½¬ç§»åˆ°å†…å­˜ï¼Œé˜²æ­¢æ˜¾å­˜ç´¯ç§¯
            all_steps_features[i] = [feat.cpu() for feat in intermediate_features]
            
            # (B) è°ƒç”¨é‡‡æ ·å™¨ï¼Œè®¡ç®—ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„ x_t
            out = sampler.sample_once(
                model=flow_model, x_t=x_t, t=t_cur, t_prev=t_prev,
                cond=cond['cond'], neg_cond=cond['neg_cond'],
                cfg_strength=cfg_strength, cfg_interval=[0, 1]
            )
            x_t = out.pred_x_prev # æ›´æ–°x_tä»¥è¿›è¡Œä¸‹ä¸€æ¬¡è¿­ä»£

    # 4. å°†é‡‡é›†åˆ°çš„æ‰€æœ‰æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶
    output_path = "intermediate_tokens2.pt"
    print(f"\n4. æ‰€æœ‰Tokensé‡‡é›†å®Œæˆï¼Œæ­£åœ¨å°†æ•°æ®ä¿å­˜åˆ° {output_path}...")
    torch.save(all_steps_features, output_path)
    print("ğŸ‰ æ•°æ®å·²æˆåŠŸä¿å­˜ï¼")
    
    # æ‰“å°ä¸€äº›ä¿¡æ¯ä»¥ä¾›éªŒè¯
    print("\n--- æ•°æ®ç»“æ„é¢„è§ˆ ---")
    print(f"æ€»å…±ä¿å­˜äº† {len(all_steps_features)} ä¸ªæ—¶é—´æ­¥çš„æ•°æ®ã€‚")
    first_step_data = all_steps_features[0]
    print(f"ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥åŒ…å« {len(first_step_data)} ä¸ªä¸­é—´å±‚çš„ç‰¹å¾ã€‚")
    first_step_first_layer_shape = first_step_data[0].shape
    print(f"å…¶ä¸­ç¬¬ä¸€ä¸ªç‰¹å¾å¼ é‡çš„å½¢çŠ¶ä¸º: {first_step_first_layer_shape}")


if __name__ == '__main__':
    print("æ­£åœ¨åŠ è½½ Pipeline æ¨¡å‹...")
    pipeline = TrellisImageTo3DPipeline.from_pretrained("microsoft/TRELLIS-image-large")
    pipeline.cuda()

    print("æ­£åœ¨åŠ è½½å›¾åƒ...")
    try:
        image = Image.open("/root/autodl-tmp/TRELLIS_8_5_copy/assets/example_image/plane.png")
    except FileNotFoundError:
        print("\né”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¤ºä¾‹å›¾ç‰‡ï¼Œè¯·ç¡®ä¿ './assets/example_image/typical_creature_rock_monster.png' è·¯å¾„æ­£ç¡®ã€‚")
        exit()

    save_intermediate_tokens_for_analysis(
        pipeline,
        image,
        seed=42,
        steps=50,
        cfg_strength=7.5
    )